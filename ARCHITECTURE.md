# ðŸ—ï¸ ARCHITECTURE - H.E.L.E.N

**DocumentaciÃ³n TÃ©cnica Completa**

## ðŸ“‹ Tabla de Contenidos

1. [VisiÃ³n General](#visiÃ³n-general)
2. [Stack TecnolÃ³gico](#stack-tecnolÃ³gico)
3. [Arquitectura del Sistema](#arquitectura-del-sistema)
4. [Componentes Frontend](#componentes-frontend)
5. [Componentes Backend](#componentes-backend)
6. [Flujo de Datos](#flujo-de-datos)
7. [APIs y Servicios Externos](#apis-y-servicios-externos)
8. [Optimizaciones y Decisiones de DiseÃ±o](#optimizaciones-y-decisiones-de-diseÃ±o)
9. [Seguridad](#seguridad)
10. [Escalabilidad](#escalabilidad)

---

## ðŸŽ¯ VisiÃ³n General

H.E.L.E.N es una arquitectura de **microservicios ligeros** con comunicaciÃ³n en tiempo real mediante WebSocket. Sigue principios de:

- **SeparaciÃ³n de responsabilidades** (Frontend/Backend)
- **Event-driven architecture** (basada en eventos)
- **Streaming de datos** (audio real-time)
- **Stateless backend** (sin estado en el servidor)
- **Client-side state management** (estado en el cliente)

### Diagrama de Alto Nivel

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          USUARIO                                 â”‚
â”‚                            â†•                                     â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                    â”‚   BROWSER    â”‚                              â”‚
â”‚                    â”‚  (Frontend)  â”‚                              â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                            â†•                                     â”‚
â”‚                        WebSocket                                 â”‚
â”‚                            â†•                                     â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                    â”‚  Node.js     â”‚                              â”‚
â”‚                    â”‚  (Backend)   â”‚                              â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                     â†™     â†“      â†˜                               â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”                          â”‚
â”‚              â”‚Whispâ”‚  â”‚Chat â”‚  â”‚11Labsâ”‚                          â”‚
â”‚              â”‚ er  â”‚  â”‚ GPT â”‚  â”‚      â”‚                          â”‚
â”‚              â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚              OpenAI    OpenAI   ElevenLabs                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ› ï¸ Stack TecnolÃ³gico

### Frontend

| TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|---------|-----------|
| **Vite** | 7.2.4 | Build tool y dev server |
| **Vanilla JS** | ES2022 | LÃ³gica de aplicaciÃ³n |
| **GSAP** | 3.x | Animaciones |
| **Socket.IO Client** | 4.8.1 | WebSocket client |
| **@ricky0123/vad-web** | 0.0.7 | Voice Activity Detection |
| **onnxruntime-web** | 1.14.0 | Runtime para modelo VAD |
| **SimplexNoise** | Latest | Generador de ruido |
| **Web Audio API** | Native | Procesamiento de audio |

### Backend

| TecnologÃ­a | VersiÃ³n | PropÃ³sito |
|------------|---------|-----------|
| **Node.js** | â‰¥20.0.0 | Runtime |
| **Express** | 4.x | HTTP server |
| **Socket.IO** | 4.x | WebSocket server |
| **OpenAI SDK** | Latest | Whisper + GPT-4 |
| **ElevenLabs SDK** | Latest | Text-to-Speech |
| **Form-data** | Latest | Multipart form handling |
| **dotenv** | Latest | Environment variables |

### Infraestructura

- **Concurrently**: Ejecutar backend y frontend simultÃ¡neamente
- **Git**: Control de versiones
- **npm**: GestiÃ³n de paquetes

---

## ðŸ›ï¸ Arquitectura del Sistema

### PatrÃ³n: Event-Driven + Microservicios

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ FRONTEND â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  VoiceAIApp  â”‚â”€â”€â”€â”€â–¶â”‚ AudioCapture â”‚                 â”‚
â”‚  â”‚   (Main)     â”‚     â”‚    (VAD)     â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚         â”‚                                                â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â–¶ AudioVisualizer                        â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â–¶ ParticleSystem                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â–¶ Socket.IO Client                       â”‚
â”‚                        â”‚                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        â–¼                    BACKEND      â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                â”‚ Socket.IO    â”‚                          â”‚
â”‚                â”‚   Server     â”‚                          â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                       â”‚                                   â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚         â”‚             â”‚             â”‚                    â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”              â”‚
â”‚    â”‚ Whisper â”‚  â”‚ ChatGPT â”‚  â”‚11Labs â”‚              â”‚
â”‚    â”‚ Service â”‚  â”‚ Service â”‚  â”‚ Service â”‚              â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

###Decisiones Clave de Arquitectura

1. **WebSocket over HTTP REST**
   - **RazÃ³n**: Latencia ultra-baja, conexiÃ³n persistente
   - **Trade-off**: MÃ¡s complejo que REST, necesita fallbacks

2. **Client-Side VAD**
   - **RazÃ³n**: Reduce carga del servidor, latencia mÃ­nima
   - **Trade-off**: Mayor carga en el navegador del cliente

3. **Stateless Backend**
   - **RazÃ³n**: FÃ¡cil de escalar horizontalmente
   - **Trade-off**: Todo el estado estÃ¡ en el cliente

4. **Streaming de Audio**
   - **RazÃ³n**: Reduce latencia percibida (TTFB)
   - **Trade-off**: Mayor complejidad en la reproducciÃ³n

---

## ðŸŽ¨ Componentes Frontend

### 1. VoiceAIApp (Main Controller)

**Archivo**: `frontend/app.js`

**Responsabilidades**:
- CoordinaciÃ³n general de la aplicaciÃ³n
- GestiÃ³n de estados (idle, listening, processing, speaking)
- InicializaciÃ³n de servicios
- Event handling principal

**Diagrama de Estados**:
```
     â”Œâ”€â”€â”€â”€â”€â”€â”
     â”‚ IDLE â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â””â”€â”€â”¬â”€â”€â”€â”˜                â”‚
        â”‚ click              â”‚
        â–¼                    â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
  â”‚ LISTENING â”‚              â”‚
  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â”‚
        â”‚ speech detected    â”‚
        â–¼                    â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
 â”‚  PROCESSING  â”‚            â”‚
 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
        â”‚ response ready     â”‚
        â–¼                    â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
  â”‚ SPEAKING â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  audio ended
```

**MÃ©todos Clave**:

```javascript
class VoiceAIApp {
    // Lifecycle
    constructor()              // InicializaciÃ³n
    async init()               // Setup completo
    
    // VAD Control
    async startVADConversation()  // Inicia escucha
    async stopVADConversation()   // Detiene sistema
    
    // WebSocket
    initializeWebSocket()      // Configura Socket.IO
    sendAudioToServer(blob)    // EnvÃ­a audio grabado
    
    // Audio Playback
    playAllAudioAtOnce()       // Reproduce respuesta
    
    // UI Updates
    setState(state)            // Cambia estado visual
    updateStatus(message)      // Actualiza mensaje
    updateSphereFromAudio(data) // Anima segun audio
}
```

### 2. AudioCaptureVAD (Voice Detection)

**Archivo**: `frontend/audioCapture.js`

**Responsabilidades**:
- Captura de audio del micrÃ³fono
- DetecciÃ³n automÃ¡tica de actividad de voz
- GestiÃ³n de chunks de audio
- Commit automÃ¡tico en silencio

**ConfiguraciÃ³n del VAD**:

```javascript
const vadConfig = {
    // Modelo ML
    model: 'silero_vad',           // Modelo Silero optimizado
    
    // DetecciÃ³n
    positiveSpeechThreshold: 0.5,   // 0-1, confianza mÃ­nima
    negativeSpeechThreshold: 0.35,  // Umbral para NO-voz
    
    // Timing
    redemptionFrames: 8,            // Frames para recuperar de silencio
    frameSamples: 1536,             // Muestras por frame
    
    // Procesamiento
    minSpeechFrames: 3,             // Frames mÃ­nimos para voz vÃ¡lida
    preSpeechPadFrames: 1,          // Padding antes de voz
    
    // Audio
    sampleRate: 16000,              // Hz (16kHz estÃ¡ndar)
    
    // Callbacks
    onFrameProcessed,               // Cada frame analizado
    onVADMisfire,                   // False positives
    onSpeechStart,                  // Inicio de voz
    onSpeechEnd,                    // Fin de voz
};
```

**Algoritmo de DetecciÃ³n**:

```javascript
/*
1. Captura frame de audio (30ms)
2. Procesa con modelo Silero VAD
3. Obtiene probabilidad de voz (0-1)
4. Si > threshold (0.5):
   - Marca como "hablando"
   - Buffer audio
5. Si < threshold y pasa tiempo (1s):
   - Marca como "silencio"
   - Commit del buffer
6. EnvÃ­a audio acumulado
*/
```

### 3. AudioVisualizer (Spectrum Analysis)

**Archivo**: `frontend/audioVisualizer.js`

**Responsabilidades**:
- AnÃ¡lisis FFT del audio
- ExtracciÃ³n de frecuencias
- Datos para visualizaciÃ³n

**Pipeline de AnÃ¡lisis**:

```
Audio Input
    â†“
MediaStreamSource / BufferSource
    â†“
AnalyserNode (FFT Size: 256)
    â†“
getByteFrequencyData() â†’ Uint8Array[128]
    â†“
NormalizaciÃ³n (0-255 â†’ 0-1)
    â†“
Datos para PartÃ­culas/Esfera
```

**ConfiguraciÃ³n FFT**:

```javascript
{
    fftSize: 256,              // Potencia de 2
    smoothingTimeConstant: 0.8, // Suavizado (0-1)
    frequencyBinCount: 128,     // fftSize / 2
    minDecibels: -90,
    maxDecibels: -10
}
```

### 4. ParticleSystem (Visual Effects)

**Archivo**: `frontend/particleSystem.js`

**Responsabilidades**:
- GestiÃ³n de 1000+ partÃ­culas
- Movimiento basado en ruido Simplex
- ReacciÃ³n a frecuencias de audio
- Rendering con requestAnimationFrame

**Algoritmo de Movimiento**:

```javascript
// Para cada partÃ­cula
particle.update(audioData, deltaTime) {
    // 1. Ruido Simplex para movimiento orgÃ¡nico
    const noiseX = simplex.noise3D(x, y, time) * speed;
    const noiseY = simplex.noise3D(x, y, time + 100) * speed;
    
    // 2. Influencia del audio (frecuencia especÃ­fica)
    const frequencyIndex = particle.id % 128;
    const audioInfluence = audioData[frequencyIndex] / 255;
    
    // 3. Combinar movimientos
    particle.x += noiseX + (audioInfluence * 0.5);
    particle.y += noiseY + (audioInfluence * 0.3);
    
    // 4. Bounds checking (wrap around)
    if (particle.x > bounds) particle.x = -bounds;
}
```

---

## âš™ï¸ Componentes Backend

### 1. Socket Handler (WebSocket Manager)

**Archivo**: `backend/routes/socketHandler.js`

**Eventos Manejados**:

| Evento | DirecciÃ³n | Payload | DescripciÃ³n |
|--------|-----------|---------|-------------|
| `connection` | Server | - | Cliente conectado |
| `audio-data` | Clientâ†’Server | `{audio: ArrayBuffer}` | Audio del usuario |
| `transcript` | Serverâ†’Client | `{text: string}` | TranscripciÃ³n de Whisper |
| `response` | Serverâ†’Client | `{text: string}` | Respuesta de ChatGPT |
| `audio-chunk` | Serverâ†’Client | `{chunk: base64, chunkNumber}` | Chunk de TTS |
| `audio-end` | Serverâ†’Client | `{totalChunks, totalTime}` | Fin de streaming |
| `status` | Serverâ†’Client | `{message, stage}` | Estado del proceso |
| `error` | Serverâ†’Client | `{message, details}` | Error |
| `disconnect` | Both | - | DesconexiÃ³n |

**Pipeline de Procesamiento**:

```javascript
async function processAudio(socket, audioData) {
    const startTime = Date.now();
    
    try {
        // 1. WHISPER - Speech to Text
        updateStatus(socket, 'whisper', 'Transcribiendo...');
        const transcript = await whisperService.transcribe(audioData);
        socket.emit('transcript', { text: transcript });
        
        // 2. CHATGPT - Generate Response
        updateStatus(socket, 'chatgpt', 'Pensando...');
        const response = await chatgptService.sendMessage(transcript);
        socket.emit('response', { text: response });
        
        // 3. ELEVENLABS - Text to Speech (STREAMING)
        updateStatus(socket, 'tts', 'Generando voz...');
        const audioStream = await elevenlabsService.streamTTS(response);
        
        // 4. CHUNK BUFFERING
        let chunkBuffer = [];
        const MIN_CHUNK_SIZE = 1000; // bytes
        
        audioStream.on('data', (chunk) => {
            chunkBuffer.push(chunk);
            const bufferSize = chunkBuffer.reduce((sum, c) => sum + c.length, 0);
            
            if (bufferSize >= MIN_CHUNK_SIZE) {
                const combined = Buffer.concat(chunkBuffer);
                socket.emit('audio-chunk', {
                    chunk: combined.toString('base64'),
                    chunkNumber: ++chunkCount,
                    mimeType: 'audio/mpeg'
                });
                chunkBuffer = [];
            }
        });
        
        audioStream.on('end', () => {
            // Flush remaining
            if (chunkBuffer.length > 0) {
                const combined = Buffer.concat(chunkBuffer);
                socket.emit('audio-chunk', {
                    chunk: combined.toString('base64'),
                    chunkNumber: ++chunkCount,
                    mimeType: 'audio/mpeg'
                });
            }
            
            socket.emit('audio-end', {
                totalChunks: chunkCount,
                totalTime: Date.now() - startTime
            });
        });
        
    } catch (error) {
        socket.emit('error', {
            message: 'Error en procesamiento',
            details: error.message,
            stage: currentStage
        });
    }
}
```

### 2. WhisperService (STT)

**Archivo**: `backend/services/WhisperService.js`

**API**: OpenAI Whisper API v1

**ConfiguraciÃ³n**:

```javascript
{
    model: 'whisper-1',
    language: 'es',           // EspaÃ±ol
    response_format: 'json',  // Opciones: json, text, srt, vtt
    temperature: 0            // DeterminÃ­stico
}
```

**Proceso**:

```javascript
async transcribe(audioBuffer) {
    // 1. Convertir Buffer a FormData
    const formData = new FormData();
    const blob = new Blob([audioBuffer], { type: 'audio/wav' });
    formData.append('file', blob, 'audio.wav');
    formData.append('model', 'whisper-1');
    formData.append('language', 'es');
    
    // 2. POST a API
    const response = await openai.audio.transcriptions.create(formData);
    
    // 3. Extraer texto
    return response.text;
}
```

**Optimizaciones**:
- Audio en formato WAV (sin compresiÃ³n adicional)
- Sample rate: 16kHz (suficiente para voz)
- Mono channel (reduce tamaÃ±o)

### 3. ChatGPTService (Conversational AI)

**Archivo**: `backend/services/ChatGPTService.js`

**API**: OpenAI Assistants API

**Arquitectura de Threads**:

```
User Session
    â†“
  Thread
    â”œâ”€â”€ Message 1 (User)
    â”œâ”€â”€ Message 2 (Assistant)
    â”œâ”€â”€ Message 3 (User)
    â”œâ”€â”€ Message 4 (Assistant)
    â””â”€â”€ ...
```

**Flujo de ConversaciÃ³n**:

```javascript
async sendMessage(userMessage) {
    // 1. Crear thread si no existe
    if (!this.currentThreadId) {
        const thread = await openai.beta.threads.create();
        this.currentThreadId = thread.id;
    }
    
    // 2. AÃ±adir mensaje del usuario
    await openai.beta.threads.messages.create(this.currentThreadId, {
        role: 'user',
        content: userMessage
    });
    
    // 3. Ejecutar asistente
    const run = await openai.beta.threads.runs.create(this.currentThreadId, {
        assistant_id: this.assistantId
    });
    
    // 4. Polling hasta completar (max 30s)
    let runStatus;
    let attempts = 0;
    const maxAttempts = 60; // 30 segundos
    
    do {
        await sleep(500);
        runStatus = await openai.beta.threads.runs.retrieve(
            this.currentThreadId,
            run.id
        );
        attempts++;
    } while (
        runStatus.status !== 'completed' && 
        attempts < maxAttempts &&
        runStatus.status !== 'failed'
    );
    
    // 5. Obtener respuesta
    const messages = await openai.beta.threads.messages.list(this.currentThreadId);
    const assistantMessage = messages.data[0];
    
    return assistantMessage.content[0].text.value;
}
```

**ConfiguraciÃ³n del Asistente**:

```javascript
{
    model: 'gpt-4-turbo',
    temperature: 0.7,          // Creatividad moderada
    max_tokens: 500,           // Respuestas concisas
    instructions: `
        Eres un asistente virtual amigable y profesional.
        Responde SIEMPRE en espaÃ±ol.
        MantÃ©n respuestas breves para conversaciones de voz.
        Usa un tono natural y conversacional.
    `
}
```

### 4. ElevenLabsService (TTS)

**Archivo**: `backend/services/ElevenLabsService.js`

**API**: ElevenLabs TTS API v1

**Streaming Configuration**:

```javascript
{
    voice_id: 'qHkrJuifPpn95wK3rm2A',  // Carmen (espaÃ±ol)
    model_id: 'eleven_multilingual_v2',
    voice_settings: {
        stability: 0.5,         // 0-1, mÃ¡s estable = menos variaciÃ³n
        similarity_boost: 0.75, // 0-1, similitud con voz original
        style: 0.0,             // 0-1, exageraciÃ³n del estilo
        use_speaker_boost: true // Mejora claridad
    },
    optimize_streaming_latency: 3  // 0-4, mÃ¡s alto = menor latencia
}
```

**Streaming Process**:

```javascript
async streamTextToSpeech(text) {
    // 1. Iniciar stream
    const response = await elevenlabs.textToSpeech(voiceId, {
        text,
        model_id: 'eleven_multilingual_v2',
        voice_settings: {...},
        optimize_streaming_latency: 3
    });
    
    // 2. Response es un stream de audio MP3
    // Eventos:
    // - 'data': Chunk de audio recibido
    // - 'end': Stream completado
    // - 'error': Error en el stream
    
    return response; // ReadableStream
}
```

---

## ðŸ“Š Flujo de Datos Completo

### Diagrama de Secuencia

```mermaid
sequenceDiagram
    participant U as Usuario
    participant F as Frontend
    participant V as VAD
    participant WS as WebSocket
    participant B as Backend
    participant W as Whisper
    participant C as ChatGPT
    participant E as ElevenLabs

    U->>F: Click en esfera
    F->>V: Iniciar VAD
    V->>U: Solicita permiso micrÃ³fono
    U->>V: Concede permiso
    
    loop Escucha Continua
        V->>V: Analiza frames (30ms)
        Note over V: Silero VAD procesa
        
        alt Voz Detectada
            V->>F: onSpeechStart()
            V->>V: Bufferiza audio
        end
        
        alt Silencio > 1s
            V->>F: onAudioCommit(audioBlob)
            F->>WS: emit('audio-data', blob)
            WS->>B: Recibe audio
            
            B->>W: transcribe(audio)
            W-->>B: texto
            B->>WS: emit('transcript', texto)
            WS->>F: Muestra transcripciÃ³n
            
            B->>C: sendMessage(texto)
            C-->>B: respuesta
            B->>WS: emit('response', respuesta)
            WS->>F: Muestra respuesta
            
            B->>E: streamTTS(respuesta)
            E-->>B: Stream de chunks
            
            loop Cada chunk
                B->>WS: emit('audio-chunk', chunk)
                WS->>F: Acumula en queue
            end
            
            E-->>B: Stream end
            B->>WS: emit('audio-end')
            WS->>F: Combina y reproduce
            
            F->>U: Reproduce voz + animaciones
        end
    end
    
    U->>F: Click para detener
    F->>V: Detiene VAD
    V->>V: Libera micrÃ³fono
```

### Latencias TÃ­picas

| Etapa | Tiempo | OptimizaciÃ³n |
|-------|--------|--------------|
| VAD Detection | 30-100ms | Client-side processing |
| Audio Upload | 100-300ms | WebSocket, compresiÃ³n |
| Whisper STT | 500-1500ms | Model optimization |
| ChatGPT Response | 1000-3000ms | Shorter prompts, streaming |
| ElevenLabs TTS (TTFB) | 300-1000ms | Streaming, latency mode 3 |
| Audio Download | 200-500ms | Chunk buffering |
| **TOTAL** | **~3-7s** | **Pipeline paralelo** |

---

## ðŸ” Seguridad

### 1. API Keys Management

```javascript
// âŒ NUNCA en cÃ³digo
const apiKey = 'sk-proj-abc123...';

// âœ… Variables de entorno
const apiKey = process.env.OPENAI_API_KEY;
```

**.env** (Git-ignored):
```env
OPENAI_API_KEY=sk-...
ELEVENLABS_API_KEY=...
```

### 2. CORS Configuration

```javascript
const corsOptions = {
    origin: process.env.FRONTEND_URL || 'http://localhost:5173',
    credentials: true,
    methods: ['GET', 'POST']
};

app.use(cors(corsOptions));
```

### 3. Rate Limiting

```javascript
// TODO: Implementar
const rateLimit = require('express-rate-limit');

const limiter = rateLimit({
    windowMs: 15 * 60 * 1000, // 15 min
    max: 100                  // requests
});

app.use('/api/', limiter);
```

### 4. Input Validation

```javascript
// Validar audio
if (!audioBuffer || audioBuffer.length === 0) {
    throw new Error('Audio vacÃ­o');
}

if (audioBuffer.length > 10 * 1024 * 1024) { // 10MB
    throw new Error('Audio demasiado grande');
}
```

---

## ðŸ“ˆ Escalabilidad

### Horizontal Scaling

```
           Load Balancer
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼        â–¼        â–¼
     Server   Server   Server
        â”‚        â”‚        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
            Redis (Session)
```

### Optimizaciones Futuras

1. **CDN para Assets**
   - Servir frontend desde CDN
   - Reduce latencia global

2. **Redis para Sesiones**
   - Compartir threads de ChatGPT
   - Persistencia entre servidores

3. **Queue para Procesamiento**
   - Bull/BullMQ con Redis
   - Procesar audio asÃ­ncronamente

4. **WebSocket Scaling**
   - Socket.IO Redis Adapter
   - Sticky sessions en load balancer

---

## ðŸ§ª Testing Strategy

### Unit Tests
```javascript
// services/WhisperService.test.js
describe('WhisperService', () => {
    it('should transcribe audio correctly', async () => {
        const audio = fs.readFileSync('test-audio.wav');
        const text = await whisper.transcribe(audio);
        expect(text).toContain('hola');
    });
});
```

### Integration Tests
```javascript
// socketHandler.test.js
describe('Audio Processing Pipeline', () => {
    it('should process audio end-to-end', async () => {
        const socket = io('http://localhost:4000');
        socket.emit('audio-data', testAudio);
        
        const transcript = await waitForEvent(socket, 'transcript');
        expect(transcript.text).toBeDefined();
        
        const response = await waitForEvent(socket, 'response');
        expect(response.text).toBeDefined();
    });
});
```

---

## ðŸ“š Referencias TÃ©cnicas

- [OpenAI Whisper API](https://platform.openai.com/docs/guides/speech-to-text)
- [OpenAI Assistants API](https://platform.openai.com/docs/assistants/overview)
- [ElevenLabs API](https://docs.elevenlabs.io/api-reference/text-to-speech)
- [Socket.IO Docs](https://socket.io/docs/v4/)
- [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)
- [Silero VAD](https://github.com/snakers4/silero-vad)

---

*Ãšltima actualizaciÃ³n: Diciembre 2024*
